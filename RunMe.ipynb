{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Introduction to Feature Extraction on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do our imports\n",
    "For this notebook we will use numpy, matplotlib, and scikit-image (imported as skimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and get a single image as an example\n",
    "Here we load in the training data, and the fine and coarse training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('./trnImage.npy')\n",
    "label_fine = np.load('./trnLabel_fine.npy')\n",
    "label_coarse = np.load('./trnLabel_coarse.npy')\n",
    "\n",
    "print(f'Images Shape: {images.shape}')\n",
    "print(f'Images Fine Labels Shape: {label_fine.shape}')\n",
    "print(f'Images Coarse Labels Shape: {label_coarse.shape}')\n",
    "image_index = 2 # pick a specific image\n",
    "image = images[:, :, :, image_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice the above shape of the data is Height$\\times{}$Width$\\times{}$Channel$\\times{}$Samples\n",
    "\n",
    "A lot of the method implementations we have used in the labs require an ordering where the samples are along the first axis (Samples$\\times{}$Height$\\times{}$Width$\\times{}$Channel) and so we need to reshape our 4D tensor. We can do this in a variety of ways, either by reshaping, transposing (or permuting/reordering dimensions), or by looping. In the below cell we will look at the different possible approaches, and why just reshaping may not be best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets call reshape on our 4D tensor\n",
    "reshaped = np.reshape(images, (50000, 32, 32, 3))\n",
    "print(f'Shape of reshaped: {reshaped.shape}')\n",
    "\n",
    "# Lets call transpose on our 4D tensor\n",
    "transposed = np.transpose(images, [3,0,1,2])\n",
    "print(f'Shape of transposed: {transposed.shape}')\n",
    "\n",
    "# Lets try looping over our 4D tensor, note how long this takes!\n",
    "new_images = []\n",
    "for i in range(images.shape[-1]):\n",
    "    new_images.append(images[:,:,:,i])\n",
    "new_images = np.asarray(new_images)\n",
    "print(f'Shape of new_images: {new_images.shape}')\n",
    "\n",
    "# Now lets look at what the result is\n",
    "plt.figure()\n",
    "plt.imshow(images[:,:,:,0])\n",
    "plt.title('Original Images')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(reshaped[0])\n",
    "plt.title('Reshaped')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(transposed[0])\n",
    "plt.title('Transposed')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(new_images[0])\n",
    "plt.title('Looped')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-crafted Feature Extractor \n",
    "The following function extracts features from a single image. It returns both the feature vector, and an image that can be plotted to show what the features represent. \n",
    "\n",
    "The feature being extracted is the _Histogram of Oriented Gradients_. For more detail on this feature you can visit https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html\n",
    "\n",
    "The feature vector is what you might use to train a model, it is the measurements observed (similar to the 13 dimensions of the Wine data, or the 4 dimensions of the Fisher Iris). The returned image is only useful to get a sense of what the features might look like on the original image, you don't need them and in fact they can be slow to compute.\n",
    "\n",
    "You may want to use such a feature extractor to obtain features to evaluate your experiements on. You may also want to explore what arguments to the $hog()$ function do, and how they may be tweaked. There are many feature extractors that you can investigate, and some models can even learn on the original feature space of the image (pixel RGB value). \n",
    "\n",
    "Note that this may take a long time to execute for the whole dataset. You may want to write your matrix of extracted features to disk as needed with $np.save()$. Tweaking the parameters to the $hog()$ method can also speed up the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from a single image\n",
    "hog_feature, hog_image = skimage.feature.hog(image, pixels_per_cell=[6,6], cells_per_block=[2,2], visualize=True) # you may need to add \"channel_axis=-1\" if you are using the newest version of skimage\n",
    "\n",
    "print(f'The extracted feature vector is of length {hog_feature.shape[0]} per sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the HoG features\n",
    "This is purely for your benefit, so that we can see roughly what the output from the $hog()$ function is actually doing. \n",
    "\n",
    "Notice that the feature extractor is providing a representation that gives an indication of the direction and intensity of the gradients within localised areas of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(hog_image)\n",
    "plt.subplot(122)\n",
    "plt.imshow(image)\n",
    "plt.suptitle(f'Extracted HOG features from image number: {image_index}\\nFine Class: {label_fine[image_index]}, Coarse Class: {label_coarse[image_index]}')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the features\n",
    "If you remember back to the labs, we were usually using data in a matrix $X$, formatted in the shape ${S}\\times{}{F}$, where ${S}$ was the number of individual samples (or data points), and ${F}$ was the number of feature dimensions for each sample.\n",
    "\n",
    "Therefore, for most of the methods we have covered, we can extract features for each sample $\\mathbf{x_i}$, which should be a vector of length $F$, and then stack them into our $S\\times{}F$ matrix to use in our experiments. \n",
    "\n",
    "Some approaches may work on slightly different shaped input, such as neural networks and convolutional neural networks. As per Lab Sheet 4, Convolutional layers usually expect an input of shape $S\\times{}H\\times{}W\\times{}C$; or *samples* $S$ which are of shape *height* $H$, *width* $W$ and *channel* $C$. Dense (Fully Connected) layers took in input of shape $S\\times{}C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "A description of the Cifar100 dataset can be found online at https://www.cs.toronto.edu/~kriz/cifar.html. This includes some baseline results and descriptions of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = tf.keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(65,100):\n",
    "    res = np.where(trn[1] == j)[0]\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.figure()\n",
    "        plt.imshow(trn[0][res[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
